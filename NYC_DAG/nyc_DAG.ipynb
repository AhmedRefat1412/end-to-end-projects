{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55415040",
   "metadata": {},
   "source": [
    "اول حاجه هنحط الداتا في مونجو دي بي "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9eaa0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Inserted 41362 documents into MongoDB successfully\n"
     ]
    }
   ],
   "source": [
    "#this is new DAG\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# 1️⃣ الاتصال بـ MongoDB\n",
    "client = MongoClient(\"mongodb://localhost:27017/\")\n",
    "\n",
    "# 2️⃣ اختيار Database و Collection\n",
    "db = client[\"nyc_data\"]\n",
    "collection = db[\"nyc_traffic\"]\n",
    "\n",
    "# (اختياري) تفريغ الكوليكشن لو بتجرب\n",
    "# collection.delete_many({})\n",
    "\n",
    "# 3️⃣ قراءة ملف الـ JSON\n",
    "with open(\"nyc_traffic.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "# تأكيد إن الداتا Array\n",
    "assert isinstance(data, list), \"JSON file must contain a list of documents\"\n",
    "\n",
    "# 4️⃣ إدخال الداتا\n",
    "collection.insert_many(data)\n",
    "\n",
    "print(f\"✅ Inserted {len(data)} documents into MongoDB successfully\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf13acc",
   "metadata": {},
   "source": [
    "حولنا الداتا بتتاعت الشوارع من ملف سي اي في اي  ملف  parquet\n",
    "ودي عشان ننوع من مصارد الداتا الي جايلنا "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9960acda",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd \n",
    "data = pd.read_csv(\"Centerline.csv\")\n",
    "data.to_parquet(\"streets_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99794ffa",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b10bd2e",
   "metadata": {},
   "source": [
    "انشاء اول تاسك في الداج وده هنعمل كونكت مع الاس 3 و هنكريت باكت \n",
    "ونعمل فيها 2 فولدر وبعدين نرفع الرو داتا فيها \n",
    "1- هنجيب الداتا  من مونجو دي بي ونرفعها علي هئيه جيسون فايل \n",
    "2- هنجيب الفايل البركيه ونرفعه \n",
    "3- هنجيب الفايل الثالث والاخير ونرفعه الي هو csv "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e009768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "# اتصال Mongo\n",
    "client = MongoClient(\"mongodb://localhost:27017\")\n",
    "db = client[\"nyc_data\"]\n",
    "collection = db[\"nyc_traffic\"]\n",
    "\n",
    "#-----------------------------------------------\n",
    "# connect with s3 \n",
    "s3 = boto3.resource(\n",
    "    's3',\n",
    "    endpoint_url='http://localhost:9010',\n",
    "    aws_access_key_id='minioadmin',\n",
    "    aws_secret_access_key='minioadmin123'\n",
    ")\n",
    "Bucket=\"datalake\"\n",
    "\n",
    "#------------------------------------------------\n",
    "# create bucket لو مش موجود \n",
    "try:\n",
    "     s3.create_bucket(Bucket=\"datalake\")\n",
    "except:\n",
    "     pass\n",
    "\n",
    "#------------------------------------------------\n",
    "# create 2 folder (raw , processed)\n",
    "try:\n",
    "     s3.put_object(Bucket=\"datalake\", Key=\"raw/\")\n",
    "     s3.put_object(Bucket=\"datalake\", Key=\"processed/\")\n",
    "except:\n",
    "     pass\n",
    "\n",
    "#----------------------------------------------------------\n",
    "# upload first file to s3 (json file)\n",
    "cursor = collection.find({}, {\"_id\": 0})\n",
    "\n",
    "data = list(cursor)          # in-memory\n",
    "json_bytes = json.dumps(\n",
    "    data,\n",
    "    ensure_ascii=False\n",
    ").encode(\"utf-8\")\n",
    "\n",
    "#load to s3\n",
    "s3.Bucket(\"datalake\").put_object(\n",
    "    Key=\"raw/mongo_traffic.json\",\n",
    "    Body=json_bytes,\n",
    "    ContentType=\"application/json\"\n",
    ")\n",
    "\n",
    "\n",
    "#---------------------------------------------------==\n",
    "# upload second file csv to s3\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url='http://localhost:9010',\n",
    "    aws_access_key_id='minioadmin',\n",
    "    aws_secret_access_key='minioadmin123'\n",
    ")\n",
    "\n",
    "\n",
    "s3_client.upload_file(\n",
    "    Filename=\"Motor_Vehicle_Collisions_Crashes.csv\",  # المسار المحلي للفايل\n",
    "    Bucket=\"datalake\",                    # اسم الباكيت في S3/MinIO\n",
    "    Key=\"raw/Motor_Vehicle_Collisions_Crashes.csv\",    # المسار داخل الباكيت\n",
    "    ExtraArgs={\"ContentType\": \"text/csv\"}   # دي زي ميتا داتا بعرفه ايه الكونتنت الي جوا الفايل ده \n",
    "\n",
    ")\n",
    "\n",
    "#--------------------------------------\n",
    "# upload the last file (parquet file )\n",
    "\n",
    "s3_client.upload_file(\n",
    "    Filename=\"streets_data.parquet\",  # المسار المحلي للفايل\n",
    "    Bucket=\"datalake\",                    # اسم الباكيت في S3/MinIO\n",
    "    Key=\"raw/streets_data.parquet\" ,   # المسار داخل الباكيت\n",
    "    ExtraArgs={\"ContentType\": \"application/octet-stream\"}  # دي زي ميتا داتا بعرفه ايه الكونتنت الي جوا الفايل ده \n",
    "\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d7dc27",
   "metadata": {},
   "source": [
    "التاسك التاني هنجيب الداتا بتاعت الجيسون فايل ونحولها لداتا فريم \n",
    "دا بستخدام باي سبارك و نعمل عليها بروسيسنج وبعدين نرفعها علي س3 تاني بس المره ده في فولدر اسمه بروسيس داتا \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6643e5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# -------------------------\n",
    "# 1️⃣ إعداد MinIO/S3\n",
    "# -------------------------\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://localhost:9010\",  # غيرها لو عندك S3 حقيقي\n",
    "    aws_access_key_id=\"minioadmin\",\n",
    "    aws_secret_access_key=\"minioadmin123\"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 2️⃣ قراءة json من S3\n",
    "# -------------------------\n",
    "obj = s3.get_object(Bucket=\"datalake\", Key=\"raw/mongo_traffic.json\")\n",
    "pdf = pd.read_csv(BytesIO(obj['Body'].read()))\n",
    "\n",
    "# -------------------------\n",
    "# 3️⃣ تحويل Pandas لـ PySpark DataFrame\n",
    "# -------------------------\n",
    "spark = (SparkSession.builder\n",
    "        .appName(\"transform 1\")\n",
    "        .getOrCreate())\n",
    "df = spark.createDataFrame(pdf)\n",
    "\n",
    "# -------------------------\n",
    "# 4️⃣ أي Processing محتاجينه\n",
    "# -------------------------\n",
    "# مثال: خلي العمود 'CRASH_DATE' كـ تاريخ\n",
    "# from pyspark.sql.functions import col, to_date\n",
    "# df = df.withColumn(\"CRASH_DATE\", to_date(col(\"CRASH_DATE\"), \"MM/dd/yyyy\"))\n",
    "\n",
    "df.show(5)\n",
    "\n",
    "# -------------------------\n",
    "# 5️⃣ تحويل PySpark DataFrame لـ Pandas\n",
    "# -------------------------\n",
    "#pdf_processed = df.toPandas()\n",
    "\n",
    "# -------------------------\n",
    "# 6️⃣ رفع CSV جديد على S3/MinIO باسم processed/\n",
    "# -------------------------\n",
    "# csv_buffer = BytesIO()\n",
    "# pdf_processed.to_csv(csv_buffer, index=False)\n",
    "\n",
    "# s3.put_object(\n",
    "#     Bucket=\"datalake\",\n",
    "#     Key=\"processed/mongo_traffic.json\",\n",
    "#     Body=csv_buffer.getvalue()\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04dda4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark)",
   "language": "python",
   "name": "spark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
